---
title: "Forecasting: Principles and Practice Chapter 5 Exercises"
author: "Neil Martin"
date: "2024-09-11"
output: html_document
---

```{r setup, include=FALSE}
load(".RData")
library(fpp3)
library(knitr)
library(ggplot2)
library(readxl)
library(dplyr)
library(readr)
library(seasonal)
library(latex2exp)
library(tsibble)
library(feasts)
library(tidyr)
```
#### Produce forecasts for the following series using whichever of NAIVE(y), SNAIVE(y) or RW(y ~ drift()) is more appropriate in each case:

#### Australian Population (global_economy)
#### Bricks (aus_production)
#### NSW Lambs (aus_livestock)
#### Household wealth (hh_budget).
#### Australian takeaway food turnover (aus_retail).

```{r model_benchmark}

global_economy |>
  filter(Country == "Australia") |>
  model(RW(Population ~ drift())) |>
  forecast(h = 5) |>
  autoplot(global_economy) +
  labs(title = "Australia Population",
       subtitle = "5 Year Population Forecast")

bricks <- aus_production |>
  filter_index("1970 Q1" ~ "2004 Q4") |>
  select(Bricks)

bricks

bricks |>
  model(SNAIVE(Bricks)) |>
  forecast(h = 5) |>
  autoplot(bricks) +
  labs(title = "Bricks",
       subtitle = "Future 5 Quarter Forecast")

aus_livestock |>
  filter(State == "New South Wales", Animal == 'Lambs') |>
  model(SNAIVE(Count)) |>
  forecast(h = 24) |>
  autoplot(aus_livestock) +
  labs(title = "Lambs in New South Wales",
       subtitle = "Dec 2018 - Dec 2020 Forecast")

hh_budget |>
  model(RW(Wealth ~ drift())) |>
  forecast(h = 5) |>
  autoplot(hh_budget) +
  labs(title = "Household Wealth",
       subtitle = "5 Year Household Wealth Forecast")

aus_retail |>
  filter(Industry == "Cafes, restaurants and takeaway food services") |>
  model(RW(Turnover ~ drift())) |>
  forecast( h = 24) |>
  autoplot(aus_retail) +
  labs(title = "Australian Takeaway Food Turnover",
       subtitle = "Apr 1982 - Dec 2018, Forecasted until Dec 2021") +
  facet_wrap(~State, scales = "free")

```   

#### Use the Facebook stock price (data set gafa_stock) to do the following:

#### Produce a time plot of the series.
#### Produce forecasts using the drift method and plot them.
#### Show that the forecasts are identical to extending the line drawn between the first and last observations.
#### Try using some of the other benchmark functions to forecast the same data set. Which do you think is best? Why?

```{r fb_stock_again}

fb_stock <- gafa_stock |>
  filter(Symbol == "FB") |>
  mutate(trading_day = row_number()) |>
  update_tsibble(index = trading_day, regular = TRUE)

fb_stock |> autoplot() +
    labs(title = "FB Stock Open Price")

fb_stock |>
  model(RW(Open ~ drift())) |>
  forecast(h = 63) |>
  autoplot(fb_stock) +
  labs(title = "FB Stock Open Price",
       y = "USD($)")

fb_stock |>
  model(RW(Open ~ drift())) |>
  forecast(h = 63) |>
  autoplot(fb_stock) +
  labs(title = "FB Stock Open Price") +
    geom_segment(aes(x = 1, y = 54.83, xend = 1258, yend = 134.45),
               colour = "red", linetype = "dashed")

fb_stock |>
  model(Drift = NAIVE(Open ~ drift()),
        Mean = MEAN(Open),
        Naive = NAIVE(Open)) |>
  forecast(h = 63) |>
  autoplot(fb_stock, level = NULL) +
  labs(title = "FB Stock Open Price",
       y = "USD($)")


```   

<p> None of the additional benchmarks are particularly useful. However, if I had to pick one it would be the drift.</p> 

#### Apply a seasonal naïve method to the quarterly Australian beer production data from 1992. Check if the residuals look like white noise, and plot the forecasts. The following code will help.

```{r whitenoise_beer}

# Extract data of interest
recent_production <- aus_production |>
  filter(year(Quarter) >= 1992)
# Define and estimate a model
fit <- recent_production |> model(SNAIVE(Beer))
# Look at the residuals
fit |> gg_tsresiduals()
# Look a some forecasts
fit |> forecast() |> autoplot(recent_production)

```   

<p> The residuals are not white noise. This can be concluded from the results from the ACF function demonstrating peaks in Q4. </p>

#### Repeat the previous exercise using the Australian Exports series from global_economy and the Bricks series from aus_production. Use whichever of NAIVE() or SNAIVE() is more appropriate in each case

```{r exports_bricks}

aus_exports <- global_economy |>
  filter(Country == "Australia")

aus_exports

fit <- aus_exports |>
  model(NAIVE(Exports))

fit |> gg_tsresiduals() +
  ggtitle("Residual Plot for Australian Exports")

fit |> forecast() |> autoplot(aus_exports) +
  ggtitle("Australian Exports")

fit <- bricks |>
  model(SNAIVE(Bricks))

fit |> gg_tsresiduals() +
  ggtitle("Residual Plot for Brick Production")

fit |> forecast() |> autoplot(bricks) +
  ggtitle("Australian Brick Production")
```   
<p> This data is not seasonal for the exports, therefore NAIVE is a better choice of model. For the Bricks data, the SNAIVE is better as this is broken down into quarters. The lag plot demonstrates clear seasonality with brick production increasing during Q4 and a reduction in production until the following quarter next year.</p>

#### Produce forecasts for the 7 Victorian series in aus_livestock using SNAIVE(). Plot the resulting forecasts including the historical data. Is this a reasonable benchmark for these series?

```{r 7_victorian_series}

aus_livestock |>
  filter(State == "Victoria") |>
  model(SNAIVE(Count ~ lag("2 years"))) |>
  forecast(h = "2 years") %>%
  autoplot(aus_livestock) +
  labs(title = "Animals in Victoria") +
  facet_wrap(~Animal, scales = "free")

```   

<p> Lambs and Calves may benefit from a trend model as overtime the number of calves has increased steadily and the number of lambs increased. For the rest, there is clear seasonal patterns within the data so a SNAIVE model is more suitable.</p>

#### Are the following statements true or false? Explain your answer.

#### Good forecast methods should have normally distributed residuals.

<p> Yes normally distributed residuals outlines that there is less of a chance of the data being white noise and the model being more accurate.</p>

#### A model with small residuals will give good forecasts.

<p> No, even though there is little difference between the forecast and the actual values, the pattern of the data might change.</p>

#### The best measure of forecast accuracy is MAPE.

<p> This is generally the most used metric.</p>

#### If your model doesn’t forecast well, you should make it more complicated.

<p> Nope, sometimes choosing a more simplistic model can provide better results.</p>

#### Always choose the model with the best forecast accuracy as measured on the test set.

<p> No, this can result in overfitting. Consider the metric the model has against the validation/testing set.</p>

#### For your retail time series (from Exercise 7 in Section 2.10):

#### Create a training dataset consisting of observations before 2011 using

```{r retail_split}

set.seed(12345678)
myseries <- aus_retail |>
  filter(`Series ID` == sample(aus_retail$`Series ID`,1))

myseries_train <- myseries |>
  filter(year(Month) < 2011)

```   

#### Check that your data have been split appropriately by producing the following plot.

```{r retail_split2}

autoplot(myseries, Turnover) +
  autolayer(myseries_train, Turnover, colour = "red")

``` 
#### Fit a seasonal naïve model using SNAIVE() applied to your training data (myseries_train).

```{r retail_split3}

fit <- myseries_train |>
  model(SNAIVE(Turnover))

``` 

#### Check the residuals.

```{r retail_split4}

fit |> gg_tsresiduals()

``` 
#### Produce forecasts for the test data

```{r retail_split5}

fc <- fit |>
  forecast(new_data = anti_join(myseries, myseries_train))
fc |> autoplot(myseries)

``` 

#### Compare the accuracy of your forecasts against the actual values.

```{r retail_split6}

fit |> accuracy()
fc |> accuracy(myseries)

```

#### Consider the number of pigs slaughtered in New South Wales (data set aus_livestock).

```{r q8}


```
